{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d55cdee6-0655-4e94-8d14-09dc067d2f2a",
   "metadata": {},
   "source": [
    "Новая структура парсера.\n",
    "\n",
    "1. Получаем ссылки на города.\n",
    "    1. Можно получить информацию с помощью гет запроса. (менее 1 мни/город)\n",
    "    2. Требуется куки браузера что бы пройти авторизацию (получается при заходе на страницу через браузер)\n",
    "2. Получаем информацию о магазинах\n",
    "    1. get \"location_info\" выдает информацию об id ключах магазинов. (менее 1 мни/город)\n",
    "    2. Так же требуется куки браузера\n",
    "3. Получаем информацию об категориях и субкатегориях\n",
    "    1. Пока единственный способ - это использовать Selenium. (1-2 час/город)\n",
    "    2. Необходимо узнать как еще можно получить эту информацию из запросов.\n",
    "4. Получаем информацию о товарах и скидке через Get запросы.\n",
    "    1. get \"item\" выдает информацию об скидках и товарах (15-30 мин/город).\n",
    "    2. Максимальное количество товара в запросе 600 единиц,\n",
    "    3. Так же 600 единиц это максимальное количество товара, которое можно ВООБЩЕ получить.\n",
    "    4. Что бы обойти это ограничение и требуется максимальная детализация в категориях/субкатегория\n",
    "5. Получение Полной информации о товаре.\n",
    "    1. в очереди"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "744ddbd6-1408-430f-944d-4e36fa1d0681",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from typing import NamedTuple\n",
    "import pandas as pd\n",
    "from urllib.parse import urlparse\n",
    "from urllib.parse import parse_qs\n",
    "import numpy as np\n",
    "import requests\n",
    "from requests.exceptions import ConnectTimeout, ChunkedEncodingError, ConnectionError\n",
    "# from tqdm import tqdm\n",
    "from tqdm.notebook import tqdm\n",
    "import sys\n",
    "from multiprocessing.dummy import Pool as ThreadPool\n",
    "from time import sleep as time_sleep\n",
    "from pprint import pprint\n",
    "tqdm.pandas()\n",
    "requests.packages.urllib3.disable_warnings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "511005a5-5847-45f3-97c8-5dfc013212df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _save_df_to_zip(df_: pd.DataFrame, archive_name: str = 'archive', folder: str='data', replace: bool=False) -> None:\n",
    "    # Путь к файлу\n",
    "    file_path = Path(folder).joinpath(archive_name + '.zip')\n",
    "    Path(folder).mkdir(exist_ok=True)\n",
    "    # Проверяем, существует ли файл\n",
    "    if file_path.exists() and not replace:\n",
    "        # Получаем время создания файла\n",
    "        time = datetime.fromtimestamp(file_path.lstat().st_atime).strftime('%Y-%m-%d %H-%M')\n",
    "\n",
    "        # Создаем новое имя файла с добавлением времени Unix\n",
    "        new_file_name = file_path.stem + \"_\" + str(time) + file_path.suffix\n",
    "\n",
    "        # Создаем новый путь для переименованного файла\n",
    "        new_file_path = file_path.with_name(new_file_name)\n",
    "        # Переименовываем файл\n",
    "        file_path.rename(new_file_path)\n",
    "\n",
    "# to csv\n",
    "    compression_opts = dict(method='zip', archive_name=f'{archive_name}.csv')\n",
    "    df_.to_csv(f'{folder}/{archive_name}.zip', index=False, compression=compression_opts, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "acd9cc34-af31-406f-9a91-15f646194d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "seg_df = pd.read_csv('data/segments.zip')\n",
    "ret_df = pd.read_csv('data/retailers.zip')\n",
    "loc_df = pd.read_csv('data/located_list.zip')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49b52bb3-1096-4c50-abb9-1fd769677879",
   "metadata": {},
   "source": [
    "## Запрос"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d51811bc-b5f0-4444-aba1-30705a06b95b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_response(url, params, headers):\n",
    "    for _ in range(5):\n",
    "        try:\n",
    "            respons = requests.get(url, params=params, headers=headers, timeout=(10, 30), verify=False)\n",
    "        except ConnectTimeout:\n",
    "            time_sleep(1)\n",
    "            continue\n",
    "        except ChunkedEncodingError:\n",
    "            time_sleep(1)\n",
    "            continue\n",
    "        except ConnectionError:\n",
    "            time_sleep(1)\n",
    "            continue\n",
    "        except Exception:\n",
    "            exc_type, exc_obj, exc_tb = sys.exc_info()\n",
    "            print(exc_type.__name__)\n",
    "            return None\n",
    "        else:    \n",
    "            return respons.json().get('items', None)\n",
    "    \n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "def get_data(pool_input: tuple[tqdm, tuple[int, str]]):\n",
    "    pbar, (index, item) = pool_input\n",
    "    \n",
    "    out_list = list()\n",
    "    \n",
    "    res = loc_df[loc_df['slug'] == item.sity].min()\n",
    "    headers = {\n",
    "                'x-locality-geoid': str(res.geoId),\n",
    "                'x-position-latitude': f'{res.lat:.5f}',\n",
    "                'x-position-longitude': f'{res.lng:.5f}'\n",
    "                }\n",
    "        \n",
    "    url = f'https://search.edadeal.io/api/v4/retailer/{item.data_uuid}/items'\n",
    "\n",
    "    params = {  'addContent': ['true'],\n",
    "                'checkAdult': ['true'],\n",
    "                'excludeSegmentSlug': ['alcohol', 'pt_alcool', 'en_alcohol', 'es_alcohol', 'tr_alkol'],\n",
    "                'groupBy': ['sku_or_meta'],\n",
    "                'numdoc': ['599'],\n",
    "                'page': ['0'],\n",
    "                'segmentUuid': []\n",
    "             }\n",
    "\n",
    "    # for su1 in tqdm(seg_df['uuid'].unique()[:], desc=f'{item.sity} / {item.market}', leave=False):\n",
    "    for su1 in seg_df['uuid'].unique()[:]:\n",
    "        params['segmentUuid'] = [su1]\n",
    "        \n",
    "        respons_1 = get_response(url, params, headers)\n",
    "        \n",
    "        if respons_1:\n",
    "            tmp_list_01 = list()\n",
    "            \n",
    "            try:\n",
    "                su2_list = list(set([(x.get('segmentUuids', []))[-1] for x in respons_1]))\n",
    "                len_sku_list = len(su2_list)\n",
    "            except Exception:\n",
    "                su2_list = None\n",
    "            \n",
    "            if not su2_list or (len_sku_list>550):\n",
    "                su2_list = seg_df[seg_df['uuid'] == su1]['uuid level 02'].unique()\n",
    "            \n",
    "            for su2 in su2_list:\n",
    "                params['segmentUuid'] = [su2]\n",
    "\n",
    "                respons_2 = get_response(url, params, headers)\n",
    "                                \n",
    "                if respons_2:\n",
    "                    tmp_list_02 = list()\n",
    "                    try:\n",
    "                        su3_list = list(set([(x.get('segmentUuids', []))[-1] for x in respons_2]))\n",
    "                        len_sku_list = len(su3_list)\n",
    "                    except Exception:\n",
    "                        su3_list = None\n",
    "                    \n",
    "                    if not su3_list or (len_sku_list>550):\n",
    "                        su3_list = seg_df[(seg_df['uuid'] == su1) & (seg_df['uuid level 02'] == su2)]['uuid level 03'].unique()\n",
    "                    \n",
    "                    for su3 in su3_list:\n",
    "                        params['segmentUuid'] = [su3]\n",
    "                        respons_3 = get_response(url, params, headers)\n",
    "\n",
    "                        if respons_3:\n",
    "                            tmp_list_02.append((su3, respons_3))\n",
    "                    \n",
    "                    if tmp_list_02:\n",
    "                        tmp_list_01.extend(tmp_list_02)\n",
    "                    else:\n",
    "                        tmp_list_01.append((su2, respons_2))\n",
    "\n",
    "            if tmp_list_01:\n",
    "                out_list.extend(tmp_list_01)\n",
    "            else:\n",
    "                out_list.append((su1, respons_1))\n",
    "        else:\n",
    "            continue\n",
    "            \n",
    "    pbar.update(1)\n",
    "    return (item, out_list)\n",
    "\n",
    "def run_get_price(list_input, cores: int=2):\n",
    "    with tqdm(total=len(list_input) ) as pbar:\n",
    "        list_to_pool = list(zip(([pbar]*len(list_input)), list_input))\n",
    "        with ThreadPool(cores) as pool:\n",
    "            work_return = pool.map(get_data, list_to_pool)\n",
    "    return work_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6e57e42e-f1be-4cc6-9967-b0f3069f37c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def separation_frame(input_df: pd.DataFrame, sep: int=5) -> list[pd.DataFrame]:\n",
    "    out_list = list()\n",
    "    chunk_size = input_df.shape[0] // int(100/sep)\n",
    "    for index in range(0, input_df.shape[0], chunk_size):\n",
    "        out_list.append(input_df.iloc[index:index+chunk_size])\n",
    "    return out_list\n",
    "\n",
    "def convert_to_df(out_list):\n",
    "    df = pd.DataFrame()\n",
    "    \n",
    "    for market, sity in out[:]:\n",
    "        for uuid, items in sity[:]:\n",
    "            for sku in items[:]:\n",
    "                tmp_df = pd.DataFrame({\n",
    "                                        'title': [sku['title']],\n",
    "                                        'sku_id': [sku.get('uuid', np.nan)],\n",
    "                                        'dateStart': [pd.to_datetime(sku.get('dateStart', np.nan), unit='ms')],\n",
    "                                        'dateEnd': [pd.to_datetime(sku.get('dateEnd', np.nan), unit='ms')],\n",
    "                                        'price': [sku.get('priceData', {}).get('new', {}).get('from', np.nan)],\n",
    "                                        'price_from': [sku.get('priceData', {}).get('new', {}).get('to', np.nan)],\n",
    "                                        'price_to': [sku.get('priceData', {}).get('new', {}).get('value', np.nan)],\n",
    "                                        'discountPercent': [sku.get('discountPercent', np.nan)],\n",
    "                                        'quantity': [sku.get('quantity', np.nan)],\n",
    "                                        'quantityUnit': [sku.get('quantityUnit', np.nan)]\n",
    "                })\n",
    "                tmp_df = pd.concat((market.to_frame().T, tmp_df), axis=1)\n",
    "                tmp_df.insert(7, 'su', uuid)\n",
    "            \n",
    "                df = pd.concat((df, tmp_df), axis=0, ignore_index=True)\n",
    "    return df\n",
    "\n",
    "def _worker_convert_to_df(pool_input):\n",
    "    df = pd.DataFrame()\n",
    "    market, sity = pool_input\n",
    "    for uuid, items in sity[:]:\n",
    "        for sku in items[:]:\n",
    "            tmp_df = pd.DataFrame({\n",
    "                                    'title': [sku['title']],\n",
    "                                    'sku_id': [sku.get('uuid', np.nan)],\n",
    "                                    'dateStart': [pd.to_datetime(sku.get('dateStart', np.nan), unit='ms')],\n",
    "                                    'dateEnd': [pd.to_datetime(sku.get('dateEnd', np.nan), unit='ms')],\n",
    "                                    'price': [sku.get('priceData', {}).get('new', {}).get('from', np.nan)],\n",
    "                                    'price_from': [sku.get('priceData', {}).get('new', {}).get('to', np.nan)],\n",
    "                                    'price_to': [sku.get('priceData', {}).get('new', {}).get('value', np.nan)],\n",
    "                                    'discountPercent': [sku.get('discountPercent', np.nan)],\n",
    "                                    'quantity': [sku.get('quantity', np.nan)],\n",
    "                                    'quantityUnit': [sku.get('quantityUnit', np.nan)]\n",
    "            })\n",
    "            tmp_df = pd.concat((market.to_frame().T, tmp_df), axis=1)\n",
    "            tmp_df.insert(7, 'su', uuid)\n",
    "        \n",
    "            df = pd.concat((df, tmp_df), axis=0, ignore_index=True)\n",
    "    return df\n",
    "\n",
    "def run_convert_to_df(list_input, cores: int=2):\n",
    "    with ThreadPool(cores) as pool:\n",
    "        work_return = pool.map(_worker_convert_to_df, list_input)\n",
    "    return work_return\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a058d08b-9bf2-4907-bc62-fa96ffa82ae6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5771072ce7b4f9db6eada85f98fc80c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/103 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time\n",
    "for index, df in list(enumerate(separation_frame(ret_df, 2)))[:1]:\n",
    "    out = run_get_price(list(df.iterrows()), cores=100)\n",
    "    out = run_convert_to_df(out, cores=50)\n",
    "    # out = pd.c\n",
    "    # _save_df_to_zip(out, f'result {index::03d}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "406ebe65-9c0d-4893-87bb-d68e0f991c34",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# pbar, (index, item) = pool_input\n",
    "item = list(ret_df.iterrows())[1][1]\n",
    "out_list = list()\n",
    "\n",
    "res = loc_df[loc_df['slug'] == item.sity].min()\n",
    "headers = {\n",
    "            'x-locality-geoid': str(res.geoId),\n",
    "            'x-position-latitude': f'{res.lat:.5f}',\n",
    "            'x-position-longitude': f'{res.lng:.5f}'\n",
    "            }\n",
    "    \n",
    "url = f'https://search.edadeal.io/api/v4/retailer/{item.data_uuid}/items'\n",
    "\n",
    "params = {  'addContent': ['true'],\n",
    "            'checkAdult': ['true'],\n",
    "            'excludeSegmentSlug': ['alcohol', 'pt_alcool', 'en_alcohol', 'es_alcohol', 'tr_alkol'],\n",
    "            'groupBy': ['sku_or_meta'],\n",
    "            'numdoc': ['599'],\n",
    "            'page': ['0'],\n",
    "            'segmentUuid': []\n",
    "         }\n",
    "\n",
    "for su1 in seg_df['uuid'].unique()[:1]:\n",
    "    params['segmentUuid'] = [su1]\n",
    "    \n",
    "    respons_1 = get_response(url, params, headers)\n",
    "    \n",
    "    if respons_1:\n",
    "        tmp_list_01 = list()\n",
    "        \n",
    "        su2_list = seg_df[seg_df['uuid'] == su1]['uuid level 02'].unique()\n",
    "        for su2 in su2_list[:]:\n",
    "            params['segmentUuid'] = [su2]\n",
    "\n",
    "            respons_2 = get_response(url, params, headers)\n",
    "                            \n",
    "            if respons_2:\n",
    "                tmp_list_02 = list()\n",
    "                try:\n",
    "                    su3_list = list(set([(x.get('segmentUuids', []))[-1] for x in respons_2]))\n",
    "                    len_sku_list = len(su3_list)\n",
    "                except Exception:\n",
    "                    su3_list = None\n",
    "                \n",
    "                if not su3_list or (len_sku_list<550):\n",
    "                    print(su3_list, end='/')\n",
    "                # su3_list = seg_df[(seg_df['uuid'] == su1) & (seg_df['uuid level 02'] == su2)]['uuid level 03'].unique()\n",
    "                \n",
    "                # for su3 in su3_list:\n",
    "                #     params['segmentUuid'] = [su3]\n",
    "                #     respons_3 = get_response(url, params, headers)\n",
    "\n",
    "                #     if respons_3:\n",
    "                #         tmp_list_02.append((su3, respons_3))\n",
    "                \n",
    "                # if tmp_list_02:\n",
    "                #     tmp_list_01.extend(tmp_list_02)\n",
    "                # else:\n",
    "                #     tmp_list_01.append((su2, respons_2))\n",
    "\n",
    "        # if tmp_list_01:\n",
    "        #     out_list.extend(tmp_list_01)\n",
    "        # else:\n",
    "        #     out_list.append((su1, respons_1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
