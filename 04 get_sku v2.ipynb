{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "76670f8e",
   "metadata": {},
   "source": [
    "- Здесь непосредственно загружаем внешнюю информацию об SKU.\n",
    "- Тут так же можно запускать весь ноутбук, правда есть несколько нюансов. (о них ниже)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "744ddbd6-1408-430f-944d-4e36fa1d0681",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 16 workers.\n",
      "INFO: Pandarallel will use standard multiprocessing data transfer (pipe) to transfer data between the main process and workers.\n",
      "\n",
      "WARNING: You are on Windows. If you detect any issue with pandarallel, be sure you checked out the Troubleshooting page:\n",
      "https://nalepae.github.io/pandarallel/troubleshooting/\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "from requests.exceptions import ConnectTimeout, ChunkedEncodingError, ConnectionError, ReadTimeout, JSONDecodeError\n",
    "# from tqdm import tqdm\n",
    "from tqdm.notebook import tqdm\n",
    "import sys\n",
    "from multiprocessing.dummy import Pool as ThreadPool\n",
    "from time import time_ns, time, sleep as time_sleep\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from pytz import timezone\n",
    "from itertools import chain\n",
    "from pandarallel import pandarallel\n",
    "\n",
    "tqdm.pandas()\n",
    "requests.packages.urllib3.disable_warnings()\n",
    "pandarallel.initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6de23daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = datetime.strftime(datetime.now(timezone('Europe/Moscow')), '%Y-%b-%d %H:%M:%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "511005a5-5847-45f3-97c8-5dfc013212df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _save_df_to_zip(df_: pd.DataFrame, archive_name: str = 'archive', folder: str='data', replace: bool=False) -> None:\n",
    "    # Путь к файлу\n",
    "    file_path = Path(folder).joinpath(archive_name + '.zip')\n",
    "    Path(folder).mkdir(exist_ok=True)\n",
    "    # Проверяем, существует ли файл\n",
    "    if file_path.exists() and not replace:\n",
    "        # Получаем время создания файла\n",
    "        time = datetime.fromtimestamp(file_path.lstat().st_atime).strftime('%Y-%m-%d %H-%M')\n",
    "\n",
    "        # Создаем новое имя файла с добавлением времени Unix\n",
    "        new_file_name = file_path.stem + \" \" + str(time) + file_path.suffix\n",
    "\n",
    "        # Создаем новый путь для переименованного файла\n",
    "        new_file_path = file_path.with_name(new_file_name)\n",
    "        # Переименовываем файл\n",
    "        file_path.rename(new_file_path)\n",
    "\n",
    "# to csv\n",
    "    compression_opts = dict(method='zip', archive_name=f'{archive_name}.csv')\n",
    "    df_.to_csv(f'{folder}/{archive_name}.zip', index=False, compression=compression_opts, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "acd9cc34-af31-406f-9a91-15f646194d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "seg_df = pd.read_csv('data/segments.zip')\n",
    "ret_df = pd.read_csv('data/retailers.zip')\n",
    "loc_df = pd.read_csv('data/located_list.zip')\n",
    "seg_id_df = pd.read_csv('data/segments_id.zip')[['uuid', 'name']].drop_duplicates(ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e502474d",
   "metadata": {},
   "source": [
    "# Function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49b52bb3-1096-4c50-abb9-1fd769677879",
   "metadata": {},
   "source": [
    "## Запрос"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d51811bc-b5f0-4444-aba1-30705a06b95b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def separation_frame(input_df: pd.DataFrame, sep: int=5) -> list[pd.DataFrame]:\n",
    "    \"\"\"\n",
    "        Функция для дробления DataFrame, что бы потом паралельно обрабатывать их паралельно.\n",
    "        sep: Сколько процентов будет занимать сегмент.\n",
    "    \"\"\"\n",
    "    out_list = list()\n",
    "    chunk_size = input_df.shape[0] // int(100/sep)\n",
    "    for index in range(0, input_df.shape[0], chunk_size):\n",
    "        out_list.append(input_df.iloc[index:index+chunk_size].reset_index())\n",
    "    return out_list\n",
    "\n",
    "\n",
    "\n",
    "def get_data(pool1_input: tuple[tqdm, int, tuple[int, str]]):\n",
    "    \n",
    "    \n",
    "    def get_response(url, params, headers):\n",
    "        for _ in range(5):\n",
    "            try:\n",
    "                respons = requests.get(url, params=params, headers=headers, timeout=(10, 30), verify=False)\n",
    "            except ConnectTimeout:\n",
    "                time_sleep(1)\n",
    "                continue\n",
    "            except ChunkedEncodingError:\n",
    "                time_sleep(1)\n",
    "                continue\n",
    "            except ConnectionError:\n",
    "                time_sleep(1)\n",
    "                continue\n",
    "            except ReadTimeout:\n",
    "                time_sleep(1)\n",
    "                continue\n",
    "            except Exception:\n",
    "                exc_type, exc_obj, exc_tb = sys.exc_info()\n",
    "                print(exc_type.__name__)\n",
    "                return None\n",
    "            else:    \n",
    "                try:\n",
    "                    return respons.json().get('items', None)\n",
    "                except JSONDecodeError:\n",
    "                    return None\n",
    "        else:\n",
    "            return None    \n",
    "\n",
    "\n",
    "    \n",
    "    def get_su2_su3(pool2_input: tuple):\n",
    "        url, params, headers, su2 = pool2_input\n",
    "        params['segmentUuid'] = [su2]\n",
    "\n",
    "        respons_2 = get_response(url, params, headers)\n",
    "                                \n",
    "        if respons_2:\n",
    "            tmp_list_02 = list()\n",
    "            try:\n",
    "                su3_list = list(set([(x.get('segmentUuids', []))[-1] for x in respons_2]))\n",
    "                len_sku_list = len(su3_list)\n",
    "            except Exception:\n",
    "                su3_list = None\n",
    "            \n",
    "            if not su3_list or (len_sku_list>550):\n",
    "                su3_list = seg_df[(seg_df['uuid'] == su1) & (seg_df['uuid level 02'] == su2)]['uuid level 03'].unique()\n",
    "            \n",
    "            for su3 in su3_list:\n",
    "                params['segmentUuid'] = [su3]\n",
    "                respons_3 = get_response(url, params, headers)\n",
    "\n",
    "                if respons_3:\n",
    "                    tmp_list_02.append((su3, respons_3))\n",
    "            \n",
    "            if tmp_list_02:\n",
    "                return tmp_list_02\n",
    "            else:\n",
    "                return [(su2, respons_2)]\n",
    "        return []\n",
    "\n",
    "    \n",
    "        \n",
    "    pbar, streams, (index, item) = pool1_input\n",
    "    \n",
    "    out_list = list()\n",
    "    \n",
    "    res = loc_df[loc_df['slug'] == item.sity].min()\n",
    "    headers = {\n",
    "                'x-locality-geoid': str(res.geoId),\n",
    "                'x-position-latitude': f'{res.lat:.5f}',\n",
    "                'x-position-longitude': f'{res.lng:.5f}'\n",
    "                }\n",
    "        \n",
    "    url = f'https://search.edadeal.io/api/v4/retailer/{item.data_uuid}/items'\n",
    "\n",
    "    params = {  'addContent': ['true'],\n",
    "                'checkAdult': ['true'],\n",
    "                'excludeSegmentSlug': ['alcohol', 'pt_alcool', 'en_alcohol', 'es_alcohol', 'tr_alkol'],\n",
    "                'groupBy': ['sku_or_meta'],\n",
    "                'numdoc': ['599'],\n",
    "                'page': ['0'],\n",
    "                'segmentUuid': []\n",
    "             }\n",
    "\n",
    "    # for su1 in tqdm(seg_df['uuid'].unique()[:], desc=f'{item.sity} / {item.market}', leave=False):\n",
    "    for su1 in seg_df['uuid'].unique()[:]:\n",
    "        params['segmentUuid'] = [su1]\n",
    "        \n",
    "        respons_1 = get_response(url, params, headers)\n",
    "        \n",
    "        if respons_1:\n",
    "            \n",
    "            try:\n",
    "                su2_list = list(set([(x.get('segmentUuids', []))[-1] for x in respons_1]))\n",
    "                len_sku_list = len(su2_list)\n",
    "            except Exception:\n",
    "                su2_list = None\n",
    "            \n",
    "            if not su2_list or (len_sku_list>550):\n",
    "                su2_list = seg_df[seg_df['uuid'] == su1]['uuid level 02'].unique()\n",
    "            \n",
    "            # !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "            with ThreadPool(streams) as pool2:\n",
    "                su2_len = len(su2_list)\n",
    "                input_list = list(zip([url]*su2_len, [params]*su2_len, [headers]*su2_len, su2_list))\n",
    "                work_return = pool2.map(get_su2_su3, input_list)    \n",
    "                tmp_list_01 = chain.from_iterable(work_return)\n",
    "                \n",
    "            if tmp_list_01:\n",
    "                out_list.extend(tmp_list_01)\n",
    "            else:\n",
    "                out_list.append((su1, respons_1))\n",
    "        else:\n",
    "            continue\n",
    "            \n",
    "    pbar.update(1)\n",
    "    return (item, out_list)\n",
    "\n",
    "def run_get_price(list_input, streams1:int=4, streams2:int=4):\n",
    "    # Первый нюанс!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "    # Функция деления на потоки.\n",
    "    # где cores - это количество потоков\n",
    "    with tqdm(total=len(list_input), desc='Download', leave=False) as pbar:\n",
    "        list_input_len = len(list_input)\n",
    "        list_to_pool = list(zip([pbar]*list_input_len, [streams2]*list_input_len, list_input))\n",
    "        with ThreadPool(streams1) as pool:\n",
    "            work_return = pool.map(get_data, list_to_pool)\n",
    "    return work_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e57e42e-f1be-4cc6-9967-b0f3069f37c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_data_to_df(input_list: list, seg_id_df) -> pd.DataFrame:\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    def convert_to_df(x: dict[str,dict[str,dict]]):\n",
    "        if not pd.isnull(x):\n",
    "            tmp_df = pd.Series({\n",
    "                                            'title': x.get('title', np.nan),\n",
    "                                            'sku_id': x.get('uuid', np.nan),\n",
    "                                            'dateStart': pd.to_datetime(x.get('dateStart', np.nan), unit='ms'),\n",
    "                                            'dateEnd': pd.to_datetime(x.get('dateEnd', np.nan), unit='ms'),\n",
    "                                            'price': x.get('priceData', {}).get('new', {}).get('from', np.nan),\n",
    "                                            'price_from': x.get('priceData', {}).get('new', {}).get('to', np.nan),\n",
    "                                            'price_to': x.get('priceData', {}).get('new', {}).get('value', np.nan),\n",
    "                                            'discountPercent': x.get('discountPercent', np.nan),\n",
    "                                            'quantity': x.get('quantity', np.nan),\n",
    "                                            'quantityUnit': x.get('quantityUnit', np.nan),\n",
    "                                            'segmentUuids': x.get('segmentUuids', np.nan),\n",
    "            })\n",
    "            \n",
    "        else:\n",
    "            tmp_df = pd.Series({\n",
    "                                            'title': np.nan,\n",
    "                                            'sku_id': np.nan,\n",
    "                                            'dateStart': pd.to_datetime(np.nan, unit='ms'),\n",
    "                                            'dateEnd': pd.to_datetime(np.nan, unit='ms'),\n",
    "                                            'price': np.nan,\n",
    "                                            'price_from': np.nan,\n",
    "                                            'price_to': np.nan,\n",
    "                                            'discountPercent': np.nan,\n",
    "                                            'quantity': np.nan,\n",
    "                                            'quantityUnit': np.nan,\n",
    "                                            'segmentUuids': np.nan,\n",
    "            })\n",
    "        return tmp_df\n",
    "        \n",
    "    start = int(time())\n",
    "    tmp_df = pd.Series(input_list, name='tmp').to_frame()\n",
    "    tmp_df[['market', 'tmp']] = tmp_df['tmp'].apply(lambda x: pd.Series(x))\n",
    "    tmp_df = pd.concat((tmp_df['market'].apply(lambda x: x), tmp_df['tmp']), axis=1)\n",
    "    tmp_df['date'] = pd.to_datetime(tmp_df['date'])\n",
    "    tmp_df = tmp_df.explode('tmp', ignore_index=True)\n",
    "    tmp_df[['uuid', 'tmp']] = tmp_df['tmp'].apply(lambda x: pd.Series(x))\n",
    "    tmp_df = tmp_df.explode('tmp', ignore_index=True)\n",
    "    # Второй нюанс!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "    # Для ускорения работы обработки данных использую паралельное вычисление,\n",
    "    # Закоментирован вариант без паралельной обработки.\n",
    "    # tmp_df = pd.concat((tmp_df, tmp_df['tmp'].apply(convert_to_df)), axis=1)\n",
    "    convert_data_before_convert = int(time()) - start\n",
    "    \n",
    "    start = int(time())\n",
    "    tmp_df = pd.concat((tmp_df, tmp_df['tmp'].parallel_apply(convert_to_df)), axis=1)\n",
    "    convert_data_convert = int(time()) - start\n",
    "    \n",
    "    start = int(time())\n",
    "    tmp_df[['su1', 'su2', 'su3']] = tmp_df['segmentUuids'].apply(lambda x: pd.Series(x))\n",
    "    tmp_df['title'] = tmp_df['title'].str.replace('\\n', ' ')\n",
    "    \n",
    "    tmp_df = tmp_df[[\n",
    "                    # 'index',\n",
    "                    'date',\n",
    "                    'sity',\n",
    "                    'market',\n",
    "                    'discounts',\n",
    "                    'data_uuid',\n",
    "                    'href',\n",
    "                    # 'tmp',\n",
    "                    # 'uuid',\n",
    "                    'su1',\n",
    "                    'su2',\n",
    "                    'su3',\n",
    "                    'title',\n",
    "                    'sku_id',\n",
    "                    'dateStart',\n",
    "                    'dateEnd',\n",
    "                    'price',\n",
    "                    'price_from',\n",
    "                    'price_to',\n",
    "                    'discountPercent',\n",
    "                    'quantity',\n",
    "                    'quantityUnit',\n",
    "                    # 'segmentUuids',\n",
    "                    ]]\n",
    "    \n",
    "    tmp_df = tmp_df.drop_duplicates(ignore_index=True)\n",
    "    \n",
    "    tmp_df['su1'] = tmp_df['su1'].to_frame().merge(\n",
    "                                                    right=seg_id_df,\n",
    "                                                    how='left',\n",
    "                                                    left_on='su1',\n",
    "                                                    right_on='uuid'\n",
    "                                                    )['name']\n",
    "\n",
    "    tmp_df['su2'] = tmp_df['su2'].to_frame().merge(\n",
    "                                                    right=seg_id_df,\n",
    "                                                    how='left',\n",
    "                                                    left_on='su2',\n",
    "                                                    right_on='uuid'\n",
    "                                                    )['name']\n",
    "\n",
    "    tmp_df['su3'] = tmp_df['su3'].to_frame().merge(\n",
    "                                                    right=seg_id_df,\n",
    "                                                    how='left',\n",
    "                                                    left_on='su3',\n",
    "                                                    right_on='uuid'\n",
    "                                                    )['name']\n",
    "    \n",
    "    tmp_df['sity'] = tmp_df['sity'].to_frame().merge(\n",
    "                                                right=loc_df,\n",
    "                                                how='left',\n",
    "                                                left_on='sity',\n",
    "                                                right_on='slug'\n",
    "                                                )['localityName']\n",
    "    \n",
    "    convert_data_after_convert = int(time()) - start\n",
    "    \n",
    "    time_df = pd.Series([convert_data_before_convert, convert_data_convert, convert_data_after_convert],\n",
    "                        index=['convert_data_before_convert', 'convert_data_convert', 'convert_data_after_convert']\n",
    "                        )\n",
    "    # return tmp_df\n",
    "    return (tmp_df, time_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a058d08b-9bf2-4907-bc62-fa96ffa82ae6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c99288362d9468d87534d6763fe360a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Total:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8db81b806b914eccbe6ebab38ba2cc20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Download:   0%|          | 0/162 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb9163de04dc44718b67251f8ad1618b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Download:   0%|          | 0/162 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b3404b75b004a18b62c1481722fd297",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Download:   0%|          | 0/162 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d1ea206949e4a35bdba409fc9204f6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Download:   0%|          | 0/162 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# %%time\n",
    "control_time = list()\n",
    "\n",
    "frame_list = separation_frame(ret_df, 3)[:4]\n",
    "with tqdm(total=len(frame_list), desc='Total') as pbar:\n",
    "    for index, df in enumerate(frame_list):\n",
    "        \n",
    "        start = int(time())\n",
    "        out = run_get_price(list(df.iterrows()), streams1=50, streams2=10)\n",
    "        get_price_time = int(time()) - start\n",
    "        \n",
    "        start = int(time())\n",
    "        out, time_df = convert_data_to_df(out, seg_id_df)\n",
    "        convert_data_time = int(time()) - start\n",
    "        \n",
    "        start = int(time())\n",
    "        # _save_df_to_zip(out, f'result {index:04d}')\n",
    "        save_time = int(time()) - start\n",
    "        \n",
    "        tmp_time_series = pd.Series([get_price_time, convert_data_time, save_time], index=['get_price_time', 'convert_data_time', 'save_time'])\n",
    "        \n",
    "        control_time.append(pd.concat((tmp_time_series, time_df)))\n",
    "        pbar.update(1)\n",
    "control_time = pd.DataFrame(control_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "316dda1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>get_price_time</th>\n",
       "      <th>convert_data_time</th>\n",
       "      <th>save_time</th>\n",
       "      <th>convert_data_before_convert</th>\n",
       "      <th>convert_data_convert</th>\n",
       "      <th>convert_data_after_convert</th>\n",
       "      <th>sum</th>\n",
       "      <th>get_price_time_d</th>\n",
       "      <th>convert_data_time_d</th>\n",
       "      <th>save_time_d</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>684</td>\n",
       "      <td>111</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>40</td>\n",
       "      <td>66</td>\n",
       "      <td>795</td>\n",
       "      <td>86</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>498</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>24</td>\n",
       "      <td>42</td>\n",
       "      <td>568</td>\n",
       "      <td>88</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>522</td>\n",
       "      <td>77</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>47</td>\n",
       "      <td>599</td>\n",
       "      <td>87</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>537</td>\n",
       "      <td>86</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>52</td>\n",
       "      <td>623</td>\n",
       "      <td>86</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   get_price_time  convert_data_time  save_time  convert_data_before_convert  \\\n",
       "0             684                111          0                            2   \n",
       "1             498                 70          0                            2   \n",
       "2             522                 77          0                            2   \n",
       "3             537                 86          0                            2   \n",
       "\n",
       "   convert_data_convert  convert_data_after_convert  sum  get_price_time_d  \\\n",
       "0                    40                          66  795                86   \n",
       "1                    24                          42  568                88   \n",
       "2                    26                          47  599                87   \n",
       "3                    30                          52  623                86   \n",
       "\n",
       "   convert_data_time_d  save_time_d  \n",
       "0                   14            0  \n",
       "1                   12            0  \n",
       "2                   13            0  \n",
       "3                   14            0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "control_time['sum'] = control_time['get_price_time'] + control_time['convert_data_time'] + control_time['save_time']\n",
    "control_time['get_price_time_d'] = round(control_time['get_price_time']/control_time['sum']*100).astype('UInt8')\n",
    "control_time['convert_data_time_d'] = round(control_time['convert_data_time']/control_time['sum']*100).astype('UInt8')\n",
    "control_time['save_time_d'] = round(control_time['save_time']/control_time['sum']*100).astype('UInt8')\n",
    "control_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "785a8075",
   "metadata": {},
   "outputs": [],
   "source": [
    "control_time.to_parquet('data/control_time_parquet.gzip', engine='pyarrow', compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bb66950b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1698070659"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(time())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dbd4135",
   "metadata": {},
   "source": [
    "## Time Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "df8ff7db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Начало: 2023-Oct-03 10:26:17\n",
      "Конец: 2023-Oct-03 14:48:14\n"
     ]
    }
   ],
   "source": [
    "end = datetime.strftime(datetime.now(timezone('Europe/Moscow')), '%Y-%b-%d %H:%M:%S')\n",
    "print(f'Начало: {start}')\n",
    "print(f'Конец: {end}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
