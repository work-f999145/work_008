{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f6fb525-c615-409d-9f7d-1cedfe50b126",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as BS\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By \n",
    "from selenium.webdriver.support.wait import WebDriverWait\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.common.exceptions import (TimeoutException,\n",
    "                                        ElementNotVisibleException, \n",
    "                                        ElementNotSelectableException, \n",
    "                                        NoSuchElementException, \n",
    "                                        ElementNotInteractableException, \n",
    "                                        StaleElementReferenceException, \n",
    "                                        ElementClickInterceptedException, \n",
    "                                        InvalidSelectorException, \n",
    "                                        WebDriverException,\n",
    "                                        NoSuchWindowException\n",
    "                                        )\n",
    "from urllib3.exceptions import NewConnectionError, MaxRetryError\n",
    "from typing import NamedTuple\n",
    "from zipfile import ZipFile, ZIP_DEFLATED\n",
    "import os, signal, sys, psutil\n",
    "import re\n",
    "from time import sleep as time_sleep, time\n",
    "from datetime import datetime\n",
    "from collections import deque\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "from itertools import chain\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import logging\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "09627a14-03b7-44e0-9d5b-d7a83427e169",
   "metadata": {},
   "outputs": [],
   "source": [
    "# получение пользовательского логгера и установка уровня логирования\n",
    "short_logger = logging.getLogger('short_logger')\n",
    "short_logger.setLevel(logging.INFO)\n",
    "\n",
    "# настройка обработчика и форматировщика в соответствии с нашими нуждами\n",
    "short_handler = logging.FileHandler(\"data/short_logger.log\", encoding='utf-8', mode='a')\n",
    "short_formatter = logging.Formatter(\"%(asctime)s %(levelname)s %(funcName)s %(message)s\")\n",
    "\n",
    "# добавление форматировщика к обработчику \n",
    "short_handler.setFormatter(short_formatter)\n",
    "# добавление обработчика к логгеру\n",
    "short_logger.addHandler(short_handler)\n",
    "\n",
    "# получение пользовательского логгера и установка уровня логирования\n",
    "long_logger = logging.getLogger('long_logger')\n",
    "long_logger.setLevel(logging.WARNING)\n",
    "\n",
    "# настройка обработчика и форматировщика в соответствии с нашими нуждами\n",
    "long_handler = logging.FileHandler(\"data/long_logger.log\", encoding='utf-8', mode='w')\n",
    "long_formatter = logging.Formatter(\"%(asctime)s %(levelname)s %(funcName)s %(message)s\")\n",
    "\n",
    "# добавление форматировщика к обработчику \n",
    "long_handler.setFormatter(long_formatter)\n",
    "# добавление обработчика к логгеру\n",
    "long_logger.addHandler(long_handler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b6ae077a-8958-46b3-b0f5-9a447dafb338",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _save_df_to_zip(df_: pd.DataFrame, archive_name: str = 'archive', folder: str='data', replace: bool=False) -> None:\n",
    "    # Путь к файлу\n",
    "    file_path = Path(folder).joinpath(archive_name + '.zip')\n",
    "    Path(folder).mkdir(exist_ok=True)\n",
    "    # Проверяем, существует ли файл\n",
    "    if file_path.exists() and not replace:\n",
    "        # Получаем время создания файла\n",
    "        time = datetime.fromtimestamp(file_path.lstat().st_atime).strftime('%Y-%m-%d %H-%M')\n",
    "\n",
    "        # Создаем новое имя файла с добавлением времени Unix\n",
    "        new_file_name = file_path.stem + \" \" + str(time) + file_path.suffix\n",
    "\n",
    "        # Создаем новый путь для переименованного файла\n",
    "        new_file_path = file_path.with_name(new_file_name)\n",
    "        # Переименовываем файл\n",
    "        file_path.rename(new_file_path)\n",
    "\n",
    "# to csv\n",
    "    compression_opts = dict(method='zip', archive_name=f'{archive_name}.csv')\n",
    "    df_.to_csv(f'{folder}/{archive_name}.zip', index=False, compression=compression_opts, encoding='utf-8')\n",
    "    \n",
    "\n",
    "def occupied_memory() -> float:\n",
    "    # Получить список всех процессов\n",
    "    all_processes = psutil.process_iter()\n",
    "\n",
    "    # Пройтись по каждому процессу и найти процессы с именем \"chrome.exe\"\n",
    "    chrome_processes = [p for p in all_processes if p.name() == \"chrome.exe\"]\n",
    "\n",
    "    # Инициализировать переменную для хранения общего объема памяти\n",
    "    total_memory = 0\n",
    "\n",
    "    # Получить информацию о памяти для каждого процесса Chrome\n",
    "\n",
    "    if chrome_processes:\n",
    "        for process in chrome_processes:\n",
    "            try:\n",
    "                memory_info = process.memory_info()\n",
    "            except psutil.NoSuchProcess:\n",
    "                memory_usage = 0\n",
    "            else:\n",
    "                memory_usage = memory_info.rss\n",
    "                total_memory += memory_usage\n",
    "\n",
    "    # Преобразовать размер в удобочитаемый формат\n",
    "    # formatted_size = psutil._common.bytes2human(total_memory)\n",
    "    return (total_memory) / (1024**2)\n",
    "\n",
    "def kill_chrome():\n",
    "    # Получить список всех процессов\n",
    "    all_processes = psutil.process_iter()\n",
    "\n",
    "    # Пройтись по каждому процессу и найти процессы с именем \"chrome.exe\"\n",
    "    chrome_processes = [p for p in all_processes if p.name() == \"chrome.exe\"]\n",
    "\n",
    "    # Получить информацию о памяти для каждого процесса Chrome\n",
    "\n",
    "    if chrome_processes:\n",
    "        for process in chrome_processes:\n",
    "            try:\n",
    "                pid = process.pid\n",
    "            except psutil.NoSuchProcess:\n",
    "                pass\n",
    "            else:\n",
    "                os.kill(pid, signal.SIGINT)\n",
    "                \n",
    "\n",
    "\n",
    "def reload_driver(driver: webdriver.Chrome, time_wait: int=5) -> webdriver.Chrome:\n",
    "    if occupied_memory() > 0:\n",
    "        kill_chrome()\n",
    "    driver = webdriver.Chrome()\n",
    "    driver.maximize_window()\n",
    "    while occupied_memory() <= 1:\n",
    "        time_sleep(0.5)\n",
    "    time_sleep(time_wait)\n",
    "    return driver\n",
    "\n",
    "def _check_load_page(driver: webdriver.Chrome, timeout: int=20, limitMB: int=1400) -> bool:\n",
    "    \"\"\"\n",
    "       Проверка наличия названия продукта в ячейке\n",
    "    \"\"\"\n",
    "    time_start = int(time())\n",
    "    while (int(time()) - time_start) < timeout:\n",
    "        n = driver.find_elements(By.XPATH, \"\"\"//div[contains(@class, \"p-dsk-srch-retailer__content\")]\n",
    "                                                //div[contains(@class, \"b-dsk-grid__container\")]\n",
    "                                                /a[contains(@class, \"p-dsk-srch-retailer__card\")]\n",
    "                                                //div[contains(@class, \"b-srch-card__price-new\")]\n",
    "                                                //span[@data-test-ref=\"money-base\"]\n",
    "                                                \"\"\")\n",
    "        \n",
    "        # Проверка на переполнение памяти:\n",
    "        if occupied_memory() > limitMB:\n",
    "            raise WebDriverMemoryOut('Превышение лимита')\n",
    "            \n",
    "        if len(n) > 0:\n",
    "            if int(n[0].text.replace('\\xa0', '').replace(' ', '')) > 0:\n",
    "                return True\n",
    "        else:\n",
    "            time_sleep(0.2)\n",
    "            continue\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fefc3e04-d21f-453d-a259-d4bf61231d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "class market_link(NamedTuple):\n",
    "    sity: str\n",
    "    market: str\n",
    "    discounts: int\n",
    "    data_uuid: str\n",
    "    href: str\n",
    "\n",
    "\n",
    "class MyNoData(Exception):\n",
    "    def __init__(self, text: str='no data'):\n",
    "        self.txt = text\n",
    "\n",
    "class MyTimeoutError(Exception):\n",
    "    def __init__(self, text: str='timeout'):\n",
    "        self.txt = text\n",
    "\n",
    "class MyLinkDifferError(Exception):\n",
    "    def __init__(self, text: str='Link Differ'):\n",
    "        self.txt = text\n",
    "\n",
    "class WebDriverMemoryOut(Exception):\n",
    "    def __init__(self, text: str='Web Driver Memory Out'):\n",
    "        self.txt = text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b9a6444d-a578-4915-afce-a146886f4f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pages_links(driver: webdriver.Chrome, url: str, pagin_sufix: str, timeout: int=30) -> list[str]:\n",
    "    \"\"\"\n",
    "        Возвращает лист с доступными ссылками\n",
    "    \"\"\"\n",
    "    \n",
    "    def data_parse(driver, wait, url, timeout):\n",
    "        time_start = int(time())\n",
    "        while (int(time()) - time_start) < timeout:\n",
    "            # Задержка действий до загрузки отслеживаемых елементов.\n",
    "            # wait.until(lambda d: d.find_element(by=By.XPATH, value=\"//nav[@aria-label='Постраничная навигация']\"))\n",
    "            wait.until(lambda d: d.find_element(by=By.XPATH, value=\"//nav[@data-test-ref='paginator']\"))\n",
    "            \n",
    "            if not (driver.current_url == url):\n",
    "                raise MyLinkDifferError()\n",
    "            \n",
    "            # Парсинг\n",
    "            page = BS(driver.page_source, 'html.parser')\n",
    "            \n",
    "            try:\n",
    "                f1 = page.find('nav', {'data-test-ref':\"paginator\"})\n",
    "            except Exception as ex:\n",
    "                print(ex)\n",
    "                raise ex\n",
    "                continue\n",
    "                \n",
    "            try:    \n",
    "                pagination = int(f1.find_all('a')[-2].text)\n",
    "            except IndexError:\n",
    "                time_sleep(0.3)\n",
    "                continue\n",
    "            \n",
    "            out_list = [f'{url}{pagin_sufix}{x}' for x in range(1, pagination+1)]\n",
    "            \n",
    "            break\n",
    "        else:\n",
    "            raise Exception(\"timeout\")\n",
    "\n",
    "        return out_list\n",
    "    \n",
    "    \n",
    "    # Класс задержки, который будет ожидать когда догрузится элемент\n",
    "    wait = WebDriverWait(\n",
    "        driver,\n",
    "        timeout=timeout + 10,\n",
    "        poll_frequency=1,\n",
    "        # ignored_exceptions=[ElementNotVisibleException, ElementNotSelectableException, NoSuchElementException]\n",
    "        )\n",
    "    # Вызов страницы\n",
    "    for _ in range(10):\n",
    "        driver.get(url)\n",
    "        try:\n",
    "            out_list =  data_parse(driver, wait, url, timeout)\n",
    "        except MyLinkDifferError:\n",
    "            time_sleep(1)\n",
    "            continue\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    return out_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "182ccd6d-7fcd-4fbe-b49a-f193bccaa7d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "loc_df = pd.read_csv('data/located_list.zip')\n",
    "catalog_markets_links = list()\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "driver.maximize_window()\n",
    "\n",
    "for index, item in loc_df.iterrows():\n",
    "    url = f'https://edadeal.ru/{item.slug}/retailers'\n",
    "    temp_url_list = get_pages_links(driver, url, '?page=')\n",
    "    catalog_markets_links.extend(list(zip([item.slug]*len(temp_url_list), temp_url_list)))\n",
    "\n",
    "driver.quit()\n",
    "len(catalog_markets_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "bb10c29e-5c77-4946-b078-e9e33fc55d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/catalog_markets_links.pickle', 'wb') as file:\n",
    "    pickle.dump(catalog_markets_links, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2acde267-4753-4aec-9ff4-0278b0447456",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/catalog_markets_links.pickle', 'rb') as file:\n",
    "    catalog_markets_links = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "73733c37-210b-454c-9e85-25f4b950b14e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reailers_parser(page: str, host: str, sity: str):\n",
    "    out_list = list()\n",
    "    \n",
    "    page = BS(page, 'html.parser')\n",
    "        \n",
    "    try:\n",
    "        f1 = page.find('div', class_='p-dsk-srch-retailers__content').find('div', class_='b-dsk-grid__container').find_all('article')\n",
    "    except AttributeError:\n",
    "        raise MyNoData()\n",
    "    \n",
    "    try:    \n",
    "        for item in f1:\n",
    "            uuid = item.get('data-uuid')\n",
    "            href = host + item.find('a').get('href')\n",
    "            title = item.find('a').find('h4').get('title')\n",
    "            discounts = int((re.findall(r'(\\d+)', item.find('a').find('p').text)[0]))\n",
    "            out_list.append(market_link(sity, title, discounts, uuid, href))\n",
    "            \n",
    "    except TypeError as ex:\n",
    "        raise MyNoData()\n",
    "\n",
    "    return out_list\n",
    "\n",
    "def get_retailers_links(driver: webdriver.Chrome, url: str, sity: str, timeout: int=30) -> list[market_link]:\n",
    "    \"\"\"\n",
    "        Возвращает лист с магазинами и ссылками.\n",
    "    \"\"\"\n",
    "    \n",
    "    host = '/'.join(url.split('/')[:-1])\n",
    "    out_list = list()\n",
    "    # Класс задержки, который будет ожидать когда догрузится элемент\n",
    "    wait = WebDriverWait(\n",
    "        driver,\n",
    "        timeout=timeout,\n",
    "        poll_frequency=1\n",
    "        )\n",
    "\n",
    "    \n",
    "    # Вызов страницы\n",
    "    driver.get(url)\n",
    "\n",
    "    if (driver.find_element(By.XPATH, \"\"\"//body\"\"\").text == 'Service unavailable'):\n",
    "        raise MyTimeoutError('timeout')\n",
    "    \n",
    "    for _ in range(10):\n",
    "        # Задержка действий до загрузки отслеживаемых елементов.\n",
    "        try:\n",
    "            wait.until(lambda d: d.find_element(by=By.XPATH, value=\"//nav[@aria-label='Постраничная навигация']\"))\n",
    "        except TimeoutException:\n",
    "            time_sleep(0.5)\n",
    "            continue\n",
    "        # Парсинг\n",
    "        try:\n",
    "            out_list.append(reailers_parser(driver.page_source, host, sity))\n",
    "        except MyNoData:\n",
    "            time_sleep(0.5)\n",
    "            continue\n",
    "        \n",
    "        break\n",
    "    \n",
    "    else:\n",
    "        raise MyTimeoutError('timeout')\n",
    "    \n",
    "    return out_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ad86045e-39d9-442f-a71c-b62801a22f5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5159\n",
      "CPU times: total: 15.8 s\n",
      "Wall time: 16min 59s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "driver = webdriver.Chrome()\n",
    "driver.maximize_window()\n",
    "temp_retailer_links = list()\n",
    "brake_list = list()\n",
    "for sity, link in catalog_markets_links:\n",
    "    for _ in range(10):\n",
    "        try:\n",
    "            temp_retailer_links.extend(get_retailers_links(driver, link, sity))\n",
    "        except MyTimeoutError:\n",
    "            continue\n",
    "        else:\n",
    "            break\n",
    "    else:\n",
    "        brake_list.append((sity, link))\n",
    "\n",
    "driver.quit()\n",
    "retailer_links = list(chain.from_iterable(temp_retailer_links))\n",
    "print(len(retailer_links))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "7bc9f7f1-210b-4286-af2a-f3811996be8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brake_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "8a17cb8d-aa12-42f5-8d1b-80b3a5aa296e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5159 entries, 0 to 5158\n",
      "Data columns (total 6 columns):\n",
      " #   Column     Non-Null Count  Dtype         \n",
      "---  ------     --------------  -----         \n",
      " 0   date       5159 non-null   datetime64[ns]\n",
      " 1   sity       5159 non-null   object        \n",
      " 2   market     5159 non-null   object        \n",
      " 3   discounts  5159 non-null   int64         \n",
      " 4   data_uuid  5159 non-null   object        \n",
      " 5   href       5159 non-null   object        \n",
      "dtypes: datetime64[ns](1), int64(1), object(4)\n",
      "memory usage: 242.0+ KB\n"
     ]
    }
   ],
   "source": [
    "retailers = pd.DataFrame(retailer_links)\n",
    "retailers.insert(0, 'date', datetime.now())\n",
    "retailers.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "491520f5-0006-4d83-b35f-33f0f2d7c724",
   "metadata": {},
   "outputs": [],
   "source": [
    "_save_df_to_zip(retailers, 'retailers')\n",
    "retailers.to_excel('data/retailers.xlsx', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
