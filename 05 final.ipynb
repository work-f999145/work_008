{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "import numpy as np\n",
    "import re\n",
    "from tqdm.notebook import tqdm\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _save_df_to_zip(df_: pd.DataFrame, archive_name: str = 'archive', folder: str='data', replace: bool=False) -> None:\n",
    "    # Путь к файлу\n",
    "    file_path = Path(folder).joinpath(archive_name + '.zip')\n",
    "    Path(folder).mkdir(exist_ok=True)\n",
    "    # Проверяем, существует ли файл\n",
    "    if file_path.exists() and not replace:\n",
    "        # Получаем время создания файла\n",
    "        time = datetime.fromtimestamp(file_path.lstat().st_atime).strftime('%Y-%m-%d %H-%M')\n",
    "\n",
    "        # Создаем новое имя файла с добавлением времени Unix\n",
    "        new_file_name = file_path.stem + \" \" + str(time) + file_path.suffix\n",
    "\n",
    "        # Создаем новый путь для переименованного файла\n",
    "        new_file_path = file_path.with_name(new_file_name)\n",
    "        # Переименовываем файл\n",
    "        file_path.rename(new_file_path)\n",
    "\n",
    "# to csv\n",
    "    compression_opts = dict(method='zip', archive_name=f'{archive_name}.csv')\n",
    "    df_.to_csv(f'{folder}/{archive_name}.zip', index=False, compression=compression_opts, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = Path('data')\n",
    "if p.exists():\n",
    "    dataframes_list = list(filter(lambda x: re.match(r'(result \\d{4}.zip)', x.name), p.iterdir()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_dates = ['date', 'dateStart', 'dateEnd']\n",
    "columns_types = {\n",
    "                    'sity':pd.StringDtype(),\n",
    "                    'market':pd.StringDtype(),\n",
    "                    'discounts':pd.UInt32Dtype(),\n",
    "                    'data_uuid':pd.StringDtype(),\n",
    "                    'href':pd.StringDtype(),\n",
    "                    'su1':pd.StringDtype(),\n",
    "                    'su2':pd.StringDtype(),\n",
    "                    'su3':pd.StringDtype(),\n",
    "                    'title':pd.StringDtype(),\n",
    "                    'sku_id':pd.StringDtype(),\n",
    "                    'price':pd.UInt32Dtype(),\n",
    "                    'price_from':pd.UInt32Dtype(),\n",
    "                    'price_to':pd.UInt32Dtype(),\n",
    "                    'discountPercent':pd.UInt32Dtype(),\n",
    "                    'quantity':pd.Float32Dtype(),\n",
    "                    'quantityUnit':pd.StringDtype(),\n",
    "                }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d69bbb2dbb2146ac8bed76ea1374ff13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Load::   0%|          | 0/34 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = list()\n",
    "for item in tqdm(dataframes_list, desc='Load:'):\n",
    "    # df.append(pd.read_csv(item, dtype_backend='pyarrow', engine='pyarrow', parse_dates=['date', 'dateStart', 'dateEnd'], dtype=columns_types))\n",
    "    df.append(pd.read_csv(item, parse_dates=columns_dates, dtype=columns_types))\n",
    "df = pd.concat(df, axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "_save_df_to_zip(df, 'result')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7795027 entries, 0 to 7795026\n",
      "Data columns (total 19 columns):\n",
      " #   Column           Dtype         \n",
      "---  ------           -----         \n",
      " 0   date             datetime64[ns]\n",
      " 1   sity             string        \n",
      " 2   market           string        \n",
      " 3   discounts        UInt32        \n",
      " 4   data_uuid        string        \n",
      " 5   href             string        \n",
      " 6   su1              string        \n",
      " 7   su2              string        \n",
      " 8   su3              string        \n",
      " 9   title            string        \n",
      " 10  sku_id           string        \n",
      " 11  dateStart        datetime64[ns]\n",
      " 12  dateEnd          datetime64[ns]\n",
      " 13  price            UInt32        \n",
      " 14  price_from       UInt32        \n",
      " 15  price_to         UInt32        \n",
      " 16  discountPercent  UInt32        \n",
      " 17  quantity         Float32       \n",
      " 18  quantityUnit     string        \n",
      "dtypes: Float32(1), UInt32(5), datetime64[ns](3), string(10)\n",
      "memory usage: 996.1 MB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('data/result.zip', parse_dates=columns_dates, dtype=columns_types)\n",
    "df.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# _save_df_to_zip(df, 'result')\n",
    "#  na_rep='null',\n",
    "df.to_csv('a:/result.csv', sep=';', index=False, decimal=',', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\f999145\\AppData\\Local\\Temp\\ipykernel_5140\\438294361.py:6: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  print(item, df[item].str.contains(r'(.*\\n.*)', regex=True).sum())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sity 0\n",
      "market 0\n",
      "data_uuid 0\n",
      "href 0\n",
      "su1 0\n",
      "su2 0\n",
      "su3 0\n",
      "title 15\n",
      "sku_id 0\n",
      "quantityUnit 0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# r = re.match(r'(.*\\n.*)', t)\n",
    "# for item in df.select_dtypes('string').columns.to_list():\n",
    "#     print(item, df[item].str.contains(r'(.*\\n.*)', regex=True).sum())\n",
    "# df.info()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
